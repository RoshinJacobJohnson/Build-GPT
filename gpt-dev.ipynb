{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt',\"r\", encoding=\"utf-8\") as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be done: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citizens, the patricians good.\\nWhat authority surfeits on would relieve us: if they\\nwould yield us but the superfluity, while it were\\nwholesome, we might guess they relieved us humanely;\\nbut they think we are too dear: the leanness that\\nafflicts us, the object of our misery, is as an\\ninventory to particularise their abundance; our\\nsufferance is a gain to them Let us revenge this with\\nour pikes, ere we become rakes: for the gods know I\\nspeak this in hunger for bread, not in thirst for revenge.\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars= sorted(list(set(text)))\n",
    "vocab_size=len(chars)\n",
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi= {e:i for i, e in enumerate(chars)}\n",
    "itos=  {i:e for i, e in enumerate(chars)}\n",
    "\n",
    "encoder=lambda s:[stoi[e] for e in s]\n",
    "decoder=lambda s:''.join(itos[e] for e in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 1, 39, 51, 1, 45, 53, 53, 42]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(\"I am good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am good'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(encoder(\"I am good\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "data=torch.tensor(encoder(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(len(data)*0.9)\n",
    "train_data=data[:n]\n",
    "val_data=data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003854"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For input tensor([18]) op is 47\n",
      "For input tensor([18, 47]) op is 56\n",
      "For input tensor([18, 47, 56]) op is 57\n",
      "For input tensor([18, 47, 56, 57]) op is 58\n",
      "For input tensor([18, 47, 56, 57, 58]) op is 1\n",
      "For input tensor([18, 47, 56, 57, 58,  1]) op is 15\n",
      "For input tensor([18, 47, 56, 57, 58,  1, 15]) op is 47\n",
      "For input tensor([18, 47, 56, 57, 58,  1, 15, 47]) op is 58\n"
     ]
    }
   ],
   "source": [
    "block_size=8\n",
    "train_x=train_data[:block_size]\n",
    "train_y=train_data[1:block_size+1]\n",
    "\n",
    "for i in range(block_size):\n",
    "    x=train_x[:i+1]\n",
    "    y=train_y[i]\n",
    "    print(\"For input {} op is {}\".format(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "block_size=8\n",
    "\n",
    "def get_batch(split):\n",
    "    data=train_data if split==\"train\" else val_data\n",
    "    ix=torch.randint(len(data)-block_size, (batch_size,))\n",
    "    x=torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    \n",
    "    return x,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb=get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs tensor([[51, 39, 63,  1, 39, 52, 57, 61],\n",
      "        [50, 47, 44, 44, 53, 56, 42,  1],\n",
      "        [52,  1, 58, 46, 43,  1, 46, 53],\n",
      "        [39, 58, 57,  1, 58, 46, 43,  1]])\n",
      "outputs tensor([[39, 63,  1, 39, 52, 57, 61, 43],\n",
      "        [47, 44, 44, 53, 56, 42,  1, 58],\n",
      "        [ 1, 58, 46, 43,  1, 46, 53, 57],\n",
      "        [58, 57,  1, 58, 46, 43,  1, 51]])\n"
     ]
    }
   ],
   "source": [
    "print(\"inputs\",xb)\n",
    "print(\"outputs\",yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For input tensor([51]) output is 39\n",
      "For input tensor([51, 39]) output is 63\n",
      "For input tensor([51, 39, 63]) output is 1\n",
      "For input tensor([51, 39, 63,  1]) output is 39\n",
      "For input tensor([51, 39, 63,  1, 39]) output is 52\n",
      "For input tensor([51, 39, 63,  1, 39, 52]) output is 57\n",
      "For input tensor([51, 39, 63,  1, 39, 52, 57]) output is 61\n",
      "For input tensor([51, 39, 63,  1, 39, 52, 57, 61]) output is 43\n",
      "For input tensor([50]) output is 47\n",
      "For input tensor([50, 47]) output is 44\n",
      "For input tensor([50, 47, 44]) output is 44\n",
      "For input tensor([50, 47, 44, 44]) output is 53\n",
      "For input tensor([50, 47, 44, 44, 53]) output is 56\n",
      "For input tensor([50, 47, 44, 44, 53, 56]) output is 42\n",
      "For input tensor([50, 47, 44, 44, 53, 56, 42]) output is 1\n",
      "For input tensor([50, 47, 44, 44, 53, 56, 42,  1]) output is 58\n",
      "For input tensor([52]) output is 1\n",
      "For input tensor([52,  1]) output is 58\n",
      "For input tensor([52,  1, 58]) output is 46\n",
      "For input tensor([52,  1, 58, 46]) output is 43\n",
      "For input tensor([52,  1, 58, 46, 43]) output is 1\n",
      "For input tensor([52,  1, 58, 46, 43,  1]) output is 46\n",
      "For input tensor([52,  1, 58, 46, 43,  1, 46]) output is 53\n",
      "For input tensor([52,  1, 58, 46, 43,  1, 46, 53]) output is 57\n",
      "For input tensor([39]) output is 58\n",
      "For input tensor([39, 58]) output is 57\n",
      "For input tensor([39, 58, 57]) output is 1\n",
      "For input tensor([39, 58, 57,  1]) output is 58\n",
      "For input tensor([39, 58, 57,  1, 58]) output is 46\n",
      "For input tensor([39, 58, 57,  1, 58, 46]) output is 43\n",
      "For input tensor([39, 58, 57,  1, 58, 46, 43]) output is 1\n",
      "For input tensor([39, 58, 57,  1, 58, 46, 43,  1]) output is 51\n"
     ]
    }
   ],
   "source": [
    "for i in range(batch_size):\n",
    "    for j in range(block_size):\n",
    "        x=xb[i,:j+1]\n",
    "        y=yb[i,j]\n",
    "        print(\"For input {} output is {}\".format(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Bigram(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table=nn.Embedding(vocab_size,vocab_size)\n",
    "        \n",
    "    def forward(self,idx,targets):\n",
    "        logits=self.token_embedding_table(idx) #B,T,C\n",
    "        b,t,c=logits.shape\n",
    "        \n",
    "        pred=logits.view(b*t,c)\n",
    "        actual_op=targets.view(b*t)\n",
    "        loss=F.cross_entropy(pred,actual_op)\n",
    "        return pred,loss\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Bigram(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred,loss=model(xb,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 65]), tensor(4.7226, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape,loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add generate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bigram(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table=nn.Embedding(vocab_size,vocab_size)\n",
    "        \n",
    "    def forward(self,idx,targets=None):\n",
    "        logits=self.token_embedding_table(idx) #B,T,C\n",
    "        if targets is None:\n",
    "            loss=None\n",
    "        else:\n",
    "            b,t,c=logits.shape\n",
    "        \n",
    "            pred=logits.view(b*t,c)\n",
    "            actual_op=targets.view(b*t)\n",
    "            loss=F.cross_entropy(pred,actual_op)\n",
    "        return logits,loss\n",
    "\n",
    "    def generate(self,idx,new_token_len):\n",
    "        \n",
    "        for i in range(new_token_len):\n",
    "            pred,loss=self(idx)\n",
    "            op=pred[:,-1,:]\n",
    "            prob=F.softmax(op,dim=-1)\n",
    "            idx_n=torch.multinomial(prob,num_samples=1)\n",
    "            idx=torch.cat([idx,idx_n],dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=torch.zeros((1,1),dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNm$nFkSxuQ.,OCJzRA:HHudd\\n suQg'it& QYjW?lcxUSRl&auQTDqaqlQ$?T!:h V!;o3SQ$oBy,:xHfLLV,BrZFVLnl\\ngxAEJe\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=Bigram(vocab_size)\n",
    "decoder(m.generate(idx,new_token_len=100)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.AdamW(m.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.483393907546997\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "\n",
    "for steps in range(100000):\n",
    "    xb,yb=get_batch(\"train\")\n",
    "    \n",
    "    logits,loss=m(xb,yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWensthe t r tinke o tifry, ou,\\nMys t akse mimyoleetaththereusthe bl. w merigod d senot aul t ound? o'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(m.generate(idx,new_token_len=100)[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "B,T,C=4,8,2\n",
    "x=torch.randn(B,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2049,  0.9165],\n",
       "        [ 0.4723, -0.6560],\n",
       "        [-1.6874, -1.0954],\n",
       "        [-0.3887,  0.6235],\n",
       "        [ 0.5212, -0.7762],\n",
       "        [-0.5422,  0.1158],\n",
       "        [ 0.0747,  0.2399],\n",
       "        [ 0.7964,  0.0137]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new=torch.zeros(B,T,C)\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        v=x[b,:t+1]\n",
    "        x_new[b,t]=torch.mean(v,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2049,  0.9165],\n",
       "        [ 0.3386,  0.1302],\n",
       "        [-0.3368, -0.2783],\n",
       "        [-0.3497, -0.0529],\n",
       "        [-0.1755, -0.1975],\n",
       "        [-0.2367, -0.1453],\n",
       "        [-0.1922, -0.0903],\n",
       "        [-0.0686, -0.0773]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2049,  0.9165],\n",
       "        [ 0.4723, -0.6560],\n",
       "        [-1.6874, -1.0954],\n",
       "        [-0.3887,  0.6235],\n",
       "        [ 0.5212, -0.7762],\n",
       "        [-0.5422,  0.1158],\n",
       "        [ 0.0747,  0.2399],\n",
       "        [ 0.7964,  0.0137]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trick-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1=torch.tril(torch.ones(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3333, 0.0000, 0.0000],\n",
       "        [0.3333, 0.5000, 0.0000],\n",
       "        [0.3333, 0.5000, 1.0000]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1/m1.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tril(torch.ones(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 2., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(a,0,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/torch.sum(a,1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tril(torch.ones(T,T))\n",
    "b=a/torch.sum(a,1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2049,  0.9165],\n",
       "         [ 0.3386,  0.1302],\n",
       "         [-0.3368, -0.2783],\n",
       "         [-0.3497, -0.0529],\n",
       "         [-0.1755, -0.1975],\n",
       "         [-0.2367, -0.1453],\n",
       "         [-0.1922, -0.0903],\n",
       "         [-0.0686, -0.0773]],\n",
       "\n",
       "        [[-0.7840, -0.2144],\n",
       "         [ 0.1645, -0.6343],\n",
       "         [ 0.3665, -0.5104],\n",
       "         [ 0.4518, -0.4599],\n",
       "         [ 0.3205, -0.4364],\n",
       "         [ 0.4775, -0.5468],\n",
       "         [ 0.2650, -0.5147],\n",
       "         [ 0.4679, -0.6071]],\n",
       "\n",
       "        [[ 1.1486, -0.1009],\n",
       "         [ 0.4030, -0.1396],\n",
       "         [ 0.2041,  0.0557],\n",
       "         [-0.3212,  0.1993],\n",
       "         [-0.4843, -0.0561],\n",
       "         [-0.5828, -0.3365],\n",
       "         [-0.5377, -0.4169],\n",
       "         [-0.4578, -0.2733]],\n",
       "\n",
       "        [[ 0.2204, -0.5008],\n",
       "         [-0.3666, -0.8449],\n",
       "         [-0.1697, -0.7573],\n",
       "         [-0.5061, -0.9290],\n",
       "         [-0.6651, -0.7110],\n",
       "         [-0.6606, -0.7147],\n",
       "         [-0.4627, -0.7977],\n",
       "         [-0.5397, -0.3950]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b@x #(B,T,T)*(B,T,C) -> (B,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tril(torch.ones(T,T))\n",
    "y=torch.zeros(T,T)\n",
    "y=y.masked_fill(a==0,float('-inf'))\n",
    "y=F.softmax(y,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "B,T,C=4,8,32\n",
    "x=torch.randn(B,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tril(torch.ones(T,T))\n",
    "w=torch.zeros(T,T)\n",
    "w=w.masked_fill(a==0,float(\"-inf\"))\n",
    "w=F.softmax(w,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=w@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_size=16\n",
    "key=nn.Linear(C,head_size,bias=False)\n",
    "query=nn.Linear(C,head_size,bias=False)\n",
    "value=nn.Linear(C,head_size,bias=False)\n",
    "\n",
    "k=key(x)\n",
    "q=query(x)\n",
    "v=value(x)\n",
    "wei=q@k.transpose(-2,-1)\n",
    "\n",
    "a=torch.tril(torch.ones(T,T))\n",
    "\n",
    "wei=wei.masked_fill(a==0,float('-inf'))\n",
    "wei=F.softmax(wei,dim=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=wei@v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8717,  1.1732, -0.0344,  0.5634,  0.6967,  0.2282, -0.5844, -1.5496,\n",
       "          1.3764,  1.2214, -0.8700,  0.1974, -0.2306,  0.1520, -1.1335, -0.4122],\n",
       "        [-0.0492,  0.3485, -0.5118,  0.3175,  0.0885,  0.4387, -0.2025, -0.5174,\n",
       "          0.5704,  0.2039, -0.8271,  0.3728,  0.1499, -0.6336, -0.5252, -0.3835],\n",
       "        [-0.4048,  0.7500, -0.2025,  0.4898,  0.3892,  0.3548, -0.3943, -1.0038,\n",
       "          1.0164,  0.6590, -0.8114,  0.2392,  0.0136, -0.2414, -0.7869, -0.3630],\n",
       "        [ 0.2487,  0.4448,  0.0811,  0.6281,  0.1360,  0.5344, -0.1691, -0.4104,\n",
       "          0.7618,  0.0273, -0.3972, -0.0949,  0.3049, -0.3410, -0.2836, -0.1495],\n",
       "        [ 0.4989,  0.2975,  0.1295,  0.5626,  0.0310,  0.5515, -0.0259, -0.1929,\n",
       "          0.4701, -0.1331, -0.1485, -0.2442,  0.2752, -0.2548, -0.0766, -0.1057],\n",
       "        [ 0.2894,  0.2507, -0.0908,  0.3814,  0.1138,  0.5175, -0.1435, -0.3582,\n",
       "          0.5902, -0.0163, -0.2699,  0.0270,  0.3231, -0.3576, -0.2075, -0.1072],\n",
       "        [ 0.2797,  0.2958,  0.0984,  0.3606,  0.2297,  0.4162, -0.2623, -0.6026,\n",
       "          0.5428,  0.0660, -0.0900,  0.0362,  0.3013, -0.0885, -0.1626, -0.2992],\n",
       "        [ 0.2901, -0.1706, -0.1339, -0.0032,  0.3312,  0.1861, -0.2512, -0.9046,\n",
       "          0.4443,  0.4830,  0.0062,  0.0755,  0.0915,  0.2242, -0.1020, -0.2368]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=y@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
